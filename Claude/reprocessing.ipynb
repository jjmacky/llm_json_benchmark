{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 10 files...\n",
      "Processing file: batch_6_unsuccessful_content_blocks.json\n",
      "Processing file: batch_2_unsuccessful_content_blocks.json\n",
      "Processing file: batch_9_unsuccessful_content_blocks.json\n",
      "Processing file: batch_5_unsuccessful_content_blocks.json\n",
      "Processing file: batch_1_unsuccessful_content_blocks.json\n",
      "Processing file: batch_10_unsuccessful_content_blocks.json\n",
      "Processing file: batch_3_unsuccessful_content_blocks.json\n",
      "Processing file: batch_7_unsuccessful_content_blocks.json\n",
      "Processing file: batch_4_unsuccessful_content_blocks.json\n",
      "Processing file: batch_8_unsuccessful_content_blocks.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the directories for input batched files and output processed files\n",
    "input_folder = 'JSON_results'\n",
    "output_folder = 'JSON_results_reprocessed'\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(\"Output folder not detected and created.\")\n",
    "\n",
    "# List only the specified batched files in the input directory\n",
    "batched_files = [f for f in os.listdir(input_folder) \n",
    "                 if re.match(r'batch_\\d+_unsuccessful_content_blocks\\.json', f)]\n",
    "print(f\"Starting to process {len(batched_files)} files...\")\n",
    "\n",
    "# Initialize empty lists to store responses\n",
    "results_columns = [\n",
    "    'error', \"error_text\",\n",
    "    'coherence_and_clarity_of_review', 'empathy_of_ai', 'behavior_of_ai', 'inappropriate_frequency',\n",
    "    'inappropriate_nature', 'ai_support_level', 'support_types', 'user_mental_state_before_ai',\n",
    "    'effect_of_ai_on_user_mental_state', 'stress_before_ai', 'effect_of_ai_on_stress', \n",
    "    'loneliness_before_ai', 'effect_of_ai_on_loneliness', 'depression_or_anxiety_before_ai',\n",
    "    'effect_of_ai_on_depression_or_anxiety', 'suicidal_thoughts_presence', 'effect_of_ai_on_suicidal_thoughts',\n",
    "    'other_despair_types', 'effect_of_ai_on_other_despair', 'user_dependence', 'real_life_relationship_impact',\n",
    "    'limitations_of_ai', 'technical_issues', 'privacy_concerns', 'feature_restriction_impact',\n",
    "    'cost_impact_on_accessibility', 'impact_of_ai_updates', 'user_satisfaction_with_policy_decisions',\n",
    "    'overall_mental_health_impact_of_company_decisions'\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "for file_name in batched_files:    \n",
    "    # Load JSON file\n",
    "    with open(os.path.join(input_folder, file_name), 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    for item in data:\n",
    "        for block in item['content_blocks']:\n",
    "            try:\n",
    "                json_string_start_index = block.find(\"{\")\n",
    "                json_string_end_index = block.rfind('}') + 1\n",
    "                json_string = block[json_string_start_index:json_string_end_index]\n",
    "                parsed_response = json.loads(json_string)\n",
    "\n",
    "                ai_mental_health = parsed_response[\"mental_health_related_to_ai\"]\n",
    "                if_unwanted_responses = ai_mental_health.get(\"if_unwanted_inappropriate_responses\", {})\n",
    "                user_mental_state = ai_mental_health[\"user_mental_state\"]\n",
    "                user_conditions = ai_mental_health[\"user_conditions\"]\n",
    "                other_despair = user_conditions.get(\"other_despair_before_using_ai\", {})\n",
    "                company_policy_impact = parsed_response[\"company_policy_impact_on_mental_health\"]\n",
    "\n",
    "                # Creating the new_row dictionary with simplified access\n",
    "                new_row = {\n",
    "                    # Error info\n",
    "                    'error': \"false\",\n",
    "                    \"error_text\": \"\",\n",
    "                    \n",
    "                    # Demographic info\n",
    "                    'coherence_and_clarity_of_review': parsed_response[\"coherence_and_clarity_of_review\"],\n",
    "                    'gender_of_user': parsed_response[\"gender_of_user\"],\n",
    "                    'gender_of_ai': parsed_response[\"gender_of_ai\"],\n",
    "                    'name_user_gave_ai': parsed_response[\"name_user_gave_ai\"],\n",
    "                    'age_of_user': parsed_response[\"age_of_user\"],\n",
    "                    'duration_of_app_usage': parsed_response[\"duration_of_app_usage\"],\n",
    "                    'frequency_of_app_usage': parsed_response[\"frequency_of_app_usage\"],\n",
    "                    'relationship_status_of_user': parsed_response[\"relationship_status_of_user\"],\n",
    "                    \n",
    "                    # AI-related fields\n",
    "                    'empathy_of_ai': ai_mental_health[\"empathy_of_ai\"],\n",
    "                    'behavior_of_ai': ai_mental_health[\"behavior_of_ai\"],\n",
    "                    'inappropriate_frequency': if_unwanted_responses.get(\"frequency\", \"\"),\n",
    "                    'inappropriate_nature': ', '.join(if_unwanted_responses.get(\"nature\", [])),\n",
    "                    'ai_support_level': ai_mental_health[\"ai_support_level\"],\n",
    "                    'support_types': ', '.join(ai_mental_health.get(\"support_types\", [])),\n",
    "                    'user_mental_state_before_ai': user_mental_state[\"before_ai_use\"],\n",
    "                    'effect_of_ai_on_user_mental_state': user_mental_state[\"effect_of_ai_use\"],\n",
    "                    \n",
    "                    # Extracting deeply nested user conditions\n",
    "                    'stress_before_ai': user_conditions[\"stress\"][\"before_ai\"],\n",
    "                    'effect_of_ai_on_stress': user_conditions[\"stress\"][\"effect_of_ai\"],\n",
    "                    'loneliness_before_ai': user_conditions[\"loneliness\"][\"before_ai\"],\n",
    "                    'effect_of_ai_on_loneliness': user_conditions[\"loneliness\"][\"effect_of_ai\"],\n",
    "                    'depression_or_anxiety_before_ai': user_conditions[\"depression_or_anxiety\"][\"before_ai\"],\n",
    "                    'effect_of_ai_on_depression_or_anxiety': user_conditions[\"depression_or_anxiety\"][\"effect_of_ai\"],\n",
    "                    'suicidal_thoughts_presence': user_conditions[\"suicidal_thoughts\"][\"presence\"],\n",
    "                    'effect_of_ai_on_suicidal_thoughts': user_conditions[\"suicidal_thoughts\"][\"effect_of_ai\"],\n",
    "                    'other_despair_types': ', '.join(other_despair.get(\"types\", [])),\n",
    "                    'effect_of_ai_on_other_despair': other_despair.get(\"effect_of_ai\", \"\"),\n",
    "                    \n",
    "                    # Other fields\n",
    "                    'user_dependence': ai_mental_health[\"user_dependence_on_ai\"],\n",
    "                    'real_life_relationship_impact': ai_mental_health[\"real_life_relationship_impact_of_ai\"],\n",
    "                    'limitations_of_ai': ', '.join(ai_mental_health.get(\"limitations_of_ai\", [])),\n",
    "                    \n",
    "                    # Company policy impact fields\n",
    "                    'technical_issues': company_policy_impact[\"technical_issues\"],\n",
    "                    'privacy_concerns': company_policy_impact[\"privacy_concerns\"],\n",
    "                    'feature_restriction_impact': company_policy_impact[\"feature_restriction_impact\"],\n",
    "                    'cost_impact_on_accessibility': company_policy_impact[\"cost_impact_on_accessibility\"],\n",
    "                    'impact_of_ai_updates': company_policy_impact[\"impact_of_ai_updates\"],\n",
    "                    'user_satisfaction_with_policy_decisions': company_policy_impact[\"user_satisfaction_with_policy_decisions\"],\n",
    "                    'overall_mental_health_impact_of_company_decisions': company_policy_impact[\"overall_mental_health_impact_of_company_decisions\"]\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                new_row['error'] = \"true\"\n",
    "                new_row['error_text'] = str(e)\n",
    "                continue\n",
    "\n",
    "            finally:\n",
    "                results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "results_df.to_csv('reprocessed_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.341137123745819"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the reprocessed CSV file\n",
    "file_path = 'reprocessed_results.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "(df['error'].sum() / len(df)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with error='true' after conversion: 0\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
